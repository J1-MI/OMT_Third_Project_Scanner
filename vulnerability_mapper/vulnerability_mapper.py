import os
import json
import sqlite3
import logging
import asyncio
import aiohttp
import requests
import xml.etree.ElementTree as ET

from configparser import ConfigParser
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from typing import List, Dict, Set

logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')


@dataclass
class ScannedService:
    ip: str
    port: int
    service_name: str
    service_version: str


def load_config(path='config.ini'):
    config = ConfigParser()
    if not os.path.exists(path):
        logging.critical(f"ì„¤ì • íŒŒì¼ '{path}' ì—†ìŒ. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit()
    config.read(path, encoding='utf-8')
    return {
        'nvd_api_key': config.get('API', 'NVDAPIKEY', fallback=''),
        'shodan_api_key': config.get('API', 'SHODANAPIKEY', fallback=None),
        'github_api_key': config.get('API', 'GITHUBAPIKEY', fallback=None),
        'otx_api_key': config.get('API', 'OTXAPIKEY', fallback=None),
        'cvss_weight': config.getfloat('SCORING', 'CVSSWEIGHT', fallback=0.5),
        'epss_weight': config.getfloat('SCORING', 'EPSSWEIGHT', fallback=0.3),
        'exploit_bonus': config.getfloat('SCORING', 'PUBLICEXPLOITBONUS', fallback=1.5),
        'threat_bonus': config.getfloat('SCORING', 'THREATINTELBONUS', fallback=2.0),
        'temporal_bonus': config.getfloat('SCORING', 'TEMPORALWEIGHTBONUS', fallback=0.1),
        'db_file': config.get('DATABASE', 'DBFILE', fallback='vulnerabilities.db'),
        'cache_ttl': config.getint('CACHE', 'TTL', fallback=604800)
    }


CONFIG = load_config()


def init_db():
    os.makedirs(os.path.dirname(CONFIG['db_file']) or '.', exist_ok=True)
    with sqlite3.connect(CONFIG['db_file']) as conn:
        cursor = conn.cursor()
        cursor.execute('''CREATE TABLE IF NOT EXISTS cve_cache (
                              key TEXT PRIMARY KEY,
                              data TEXT NOT NULL,
                              cached_at TEXT NOT NULL
                          )''')
        cursor.execute('''CREATE TABLE IF NOT EXISTS scan_logs (
                              id INTEGER PRIMARY KEY AUTOINCREMENT,
                              timestamp TEXT,
                              input_data TEXT,
                              cve_id TEXT,
                              risk_score REAL,
                              risk_rating TEXT
                          )''')
        conn.commit()


def load_kev_catalog() -> Set[str]:
    try:
        url = "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json"
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        data = resp.json()
        kev_set = {vuln['cveID'] for vuln in data.get('vulnerabilities', [])}
        logging.info(f"CISA KEV ë¡œë“œ ì™„ë£Œ: {len(kev_set)}ê±´")
        return kev_set
    except Exception as e:
        logging.error(f"CISA KEV ë¡œë“œ ì‹¤íŒ¨: {e}")
        return set()


async def get_from_cache_or_api(session: aiohttp.ClientSession, key: str, api_call):
    with sqlite3.connect(CONFIG['db_file']) as conn:
        cursor = conn.cursor()
        row = cursor.execute("SELECT data, cached_at FROM cve_cache WHERE key = ?", (key,)).fetchone()
        if row:
            data, cached_at = row
            if datetime.now() - datetime.fromisoformat(cached_at) < timedelta(seconds=CONFIG['cache_ttl']):
                return json.loads(data)
    try:
        data = await api_call(session, key)
        if data is not None:
            with sqlite3.connect(CONFIG['db_file']) as conn:
                cursor = conn.cursor()
                cursor.execute("REPLACE INTO cve_cache VALUES (?, ?, ?)", (key, json.dumps(data), datetime.now().isoformat()))
                conn.commit()
            return data
    except Exception as e:
        logging.error(f"API í˜¸ì¶œ ì‹¤íŒ¨ ({key}): {e}")
    return None


async def api_get_cve_details(session, cve_id):
    headers = {}
    if CONFIG['nvd_api_key'] and CONFIG['nvd_api_key'].lower() != 'notused':
        headers['apiKey'] = CONFIG['nvd_api_key']
    url = f"https://services.nvd.nist.gov/rest/json/cves/2.0?cveId={cve_id}"
    try:
        async with session.get(url, headers=headers, timeout=10) as resp:
            resp.raise_for_status()
            vuln_data = (await resp.json())['vulnerabilities'][0]['cve']
            base_score = vuln_data.get('metrics', {}).get('cvssMetricV31', [{}])[0].get('cvssData', {}).get('baseScore', 0)
            desc = vuln_data['descriptions'][0]['value'] if vuln_data['descriptions'] else ""
            pub_date = vuln_data.get('published')
            return {'cve_id': cve_id, 'cvss_score': base_score, 'description': desc,
                    'published_date': pub_date, 'epss_percentile': 0.0}
    except Exception as e:
        logging.warning(f"NVD API ì˜¤ë¥˜ ({cve_id}): {e}")
        return {'cve_id': cve_id, 'cvss_score': 0.0, 'description': 'NVD ë°ì´í„° ì—†ìŒ',
                'published_date': None, 'epss_percentile': 0.0}


def get_epss_score(cve_id):
    url = f"https://api.first.org/data/v1/epss?cve={cve_id}"
    try:
        resp = requests.get(url, timeout=5)
        resp.raise_for_status()
        data = resp.json().get('data', [])
        if data:
            return float(data[0].get('epss', 0))
    except Exception as e:
        logging.warning(f"EPSS í˜¸ì¶œ ì‹¤íŒ¨: {e}")
    return 0.0


async def get_shodan_info(session, ip):
    if not CONFIG['shodan_api_key']:
        return {}
    url = f"https://api.shodan.io/shodan/host/{ip}?key={CONFIG['shodan_api_key']}"
    try:
        async with session.get(url, timeout=10) as resp:
            if resp.status != 200:
                logging.warning(f"Shodan API ì‹¤íŒ¨ ìƒíƒœ {resp.status} (IP: {ip})")
                return {}
            return await resp.json()
    except Exception as e:
        logging.error(f"Shodan ì¡°íšŒ ì‹¤íŒ¨ (IP: {ip}): {e}")
        return {}


async def get_github_exploit(session, cve_id):
    if not CONFIG['github_api_key']:
        return []
    url = f"https://api.github.com/search/repositories?q={cve_id}+exploit"
    headers = {"Authorization": f"token {CONFIG['github_api_key']}"}
    try:
        async with session.get(url, headers=headers, timeout=10) as resp:
            if resp.status != 200:
                logging.warning(f"GitHub API ì‹¤íŒ¨ ìƒíƒœ {resp.status} (CVE: {cve_id})")
                return []
            data = await resp.json()
            return [item['html_url'] for item in data.get('items', [])[:3]]
    except Exception as e:
        logging.error(f"GitHub API ì˜¤ë¥˜ (CVE: {cve_id}): {e}")
        return []


async def get_otx_info(session, ip):
    if not CONFIG['otx_api_key']:
        return []
    url = f"https://otx.alienvault.com/api/v1/indicators/IPv4/{ip}/general"
    headers = {'X-OTX-API-KEY': CONFIG['otx_api_key']}
    try:
        async with session.get(url, headers=headers, timeout=10) as resp:
            if resp.status != 200:
                logging.warning(f"OTX API ì‹¤íŒ¨ ìƒíƒœ {resp.status} (IP: {ip})")
                return []
            data = await resp.json()
            pulses = data.get('pulse_info', {}).get('pulses', [])
            keywords = []
            for pulse in pulses:
                name = pulse.get('name', '').lower()
                if 'ransomware' in name:
                    keywords.append('Ransomware')
                if 'malware' in name:
                    keywords.append('Malware')
            return list(set(keywords))
    except Exception as e:
        logging.error(f"OTX ì¡°íšŒ ì‹¤íŒ¨ (IP: {ip}): {e}")
        return []


def calculate_risk_score(details, context, asset_importance=1.0, kev_catalog=set()):
    cve_id = details.get('cve_id', '')
    if cve_id in kev_catalog:
        return 10.0, 'ğŸš¨ URGENT (Actively Exploited)'
    cvss = details.get('cvss_score', 0)
    epss = details.get('epss_percentile', 0)
    score = (cvss * CONFIG['cvss_weight'] + (epss / 10) * CONFIG['epss_weight']) * asset_importance
    if context.get('has_public_exploit'):
        score += CONFIG['exploit_bonus']
    if context.get('threat_keywords'):
        score += CONFIG['threat_bonus']
    temporal_bonus = 0.0
    pub = details.get('published_date')
    if pub:
        published_date = datetime.fromisoformat(pub.replace('Z', '+00:00'))
        if datetime.now(published_date.tzinfo) - published_date < timedelta(days=90):
            temporal_bonus = CONFIG['temporal_bonus']
    score = min(10.0, round(score + temporal_bonus, 2))
    if score >= 9:
        rating = 'Critical'
    elif score >= 7:
        rating = 'High'
    elif score >= 4:
        rating = 'Medium'
    else:
        rating = 'Low'
    return score, rating


def parse_nmap_xml(file_path: str) -> List[ScannedService]:
    """
    Nmap XML ìŠ¤ìº” ê²°ê³¼ë¥¼ íŒŒì‹±í•´ ScannedService ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    services = []
    tree = ET.parse(file_path)
    root = tree.getroot()

    for host in root.findall('host'):
        ip = None
        for addr in host.findall('address'):
            if addr.get('addrtype') == 'ipv4':
                ip = addr.get('addr')
                break
        if not ip:
            continue

        for port in root.findall('./ports/port'):
            portid = port.get('portid')
            service_elem = port.find('service')
            service_name = service_elem.get('name') if service_elem is not None else 'unknown'
            service_version = service_elem.get('version') if (service_elem is not None and 'version' in service_elem.attrib) else ''
            services.append(ScannedService(ip=ip,
                                           port=int(portid),
                                           service_name=service_name,
                                           service_version=service_version))
    return services


def parse_scan_result(file_path: str) -> List[ScannedService]:
    """
    JSON í˜¹ì€ Nmap XML í¬ë§· ì…ì¶œë ¥ ëŒ€ë¹„ ìë™ íŒŒì‹± í•¨ìˆ˜
    """
    if file_path.endswith('.json'):
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            services = []
            for entry in data:
                services.append(ScannedService(
                    ip=entry.get('ip') or entry.get('host') or '',
                    port=int(entry.get('port')),
                    service_name=entry.get('service_name') or entry.get('servicename') or '',
                    service_version=entry.get('service_version') or entry.get('serviceversion') or ''
                ))
            return services

    elif file_path.endswith('.xml'):
        return parse_nmap_xml(file_path)

    else:
        raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í™•ì¥ìì…ë‹ˆë‹¤. JSON ë˜ëŠ” XMLë§Œ ì§€ì›í•©ë‹ˆë‹¤.")


async def analyze_services(services: List[ScannedService], asset_importance_map: Dict[str, float] = {}, kev_catalog: Set[str] = set()):
    results = {}
    async with aiohttp.ClientSession() as session:
        for service in services:
            logging.info(f"ë¶„ì„: {service.service_name} @ {service.ip}:{service.port}")
            shodan_task = asyncio.create_task(get_shodan_info(session, service.ip))
            otx_task = asyncio.create_task(get_otx_info(session, service.ip))

            headers = {}
            if CONFIG['nvd_api_key'] and CONFIG['nvd_api_key'].lower() != 'notused':
                headers['apiKey'] = CONFIG['nvd_api_key']
            params = {'keywordSearch': f"{service.service_name} {service.service_version}", 'resultsPerPage': 10}

            try:
                async with session.get("https://services.nvd.nist.gov/rest/json/cves/2.0", headers=headers, params=params, timeout=10) as resp:
                    resp.raise_for_status()
                    cve_list = (await resp.json()).get('vulnerabilities', [])
                    cve_ids = [v['cve']['id'] for v in cve_list]
            except Exception as e:
                logging.error(f"CVE ê²€ìƒ‰ ì‹¤íŒ¨ ({service.service_name}): {e}")
                cve_ids = []

            vulnerabilities = []
            for cve_id in cve_ids:
                details = await get_from_cache_or_api(session, cve_id, api_get_cve_details)
                details['epss_percentile'] = get_epss_score(cve_id)
                exploits = await get_github_exploit(session, cve_id)
                context = {
                    'has_public_exploit': bool(exploits),
                    'threat_keywords': await otx_task
                }
                risk_score, risk_rating = calculate_risk_score(details, context, asset_importance_map.get(service.ip, 1.0), kev_catalog)

                with sqlite3.connect(CONFIG['db_file']) as conn:
                    conn.cursor().execute("INSERT INTO scan_logs VALUES (NULL, ?, ?, ?, ?, ?)",
                                          (datetime.now().isoformat(), json.dumps(asdict(service), ensure_ascii=False), cve_id, risk_score, risk_rating))
                    conn.commit()

                vulnerabilities.append({
                    'cve_id': cve_id,
                    'description': details.get('description', ''),
                    'cvss_score': details.get('cvss_score', 0),
                    'epss_score': details.get('epss_percentile', 0),
                    'exploit_count': len(exploits),
                    'risk_score': risk_score,
                    'risk_rating': risk_rating,
                    'context': context,
                    'exploit_links': exploits
                })

            shodan_info = await shodan_task
            results[f"{service.ip}:{service.port}"] = {
                'service': asdict(service),
                'shodan_info': shodan_info,
                'vulnerabilities': sorted(vulnerabilities, key=lambda x: x['risk_score'], reverse=True)
            }
    return results


async def main():
    import sys
    # í™•ì‹¤í•˜ê²Œ íŒŒì¼ëª…ì€ ì½”ë“œ ë‚´ì— ê³ ì •, ëª…ë ¹í–‰ ì¸ì ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    scan_result_file = "your_actual_scan_results.json"  # ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ê¼­ ë°”ê¾¸ì‹­ì‹œì˜¤

    init_db()
    kev_catalog = load_kev_catalog()
    assets = parse_scan_result(scan_result_file)
    asset_importance = {svc.ip: 1.0 for svc in assets}  # í•„ìš”ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥
    results = await analyze_services(assets, asset_importance, kev_catalog)
    print(json.dumps(results, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    asyncio.run(main())
